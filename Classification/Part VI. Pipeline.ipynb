{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Preprocessing \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer # it makes functions compatible with scikit-learn pipelines\n",
    "from sklearn.pipeline import Pipeline   # Sequentially apply a list of transformations\n",
    "from sklearn.compose import ColumnTransformer # Applies in parallel transformations to columns\n",
    "\n",
    "# Grid search \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# pipeline visualization (only if sklearn version = 0.23.1)\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Practice/master/Data/titanic.csv'\n",
    "titanic = pd.read_csv(url)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical features**:\n",
    "- Age\n",
    "- Fare\n",
    "\n",
    "**Categorical features**:\n",
    "- Sex\n",
    "- Ticket\n",
    "- Cabin\n",
    "- Embarked (Port of Embarkation: C, Q, and S)\n",
    "\n",
    "**Ordinal features**:\n",
    "- Pclass (passenger class)\n",
    "- SibSp (number of siblings / spouses aboard the Titanic)\n",
    "- Parch (number of parents / children aboard the Titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of missing values\n",
    "100*titanic.isnull().sum()/len(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix/ target vector\n",
    "feature_cols = ['Pclass','Name','Sex','Age','SibSp','Parch','Fare','Embarked']\n",
    "X = titanic[feature_cols] \n",
    "y = titanic.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Name.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title feature\n",
    "titles = titanic.Name.apply(lambda x: x.split(\",\")[1].split(\".\")[0].strip())\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles.value_counts().plot(kind='bar',figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family size\n",
    "family_size = titanic.SibSp+titanic.Parch+1\n",
    "family_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family_size(dataframe):\n",
    "    return dataframe.assign(Family_size=dataframe.SibSp + dataframe.Parch + 1)\n",
    "def get_title(dataframe):\n",
    "    return dataframe.assign(Title=dataframe.Name.apply(lambda x: x.split(\",\")[1].split(\".\")[0].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for the pipeline\n",
    "family_size_processor = FunctionTransformer(get_family_size)\n",
    "title_processor = FunctionTransformer(get_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute+scale\n",
    "numeric_features = ['Age', 'Fare']\n",
    "numeric_processor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Embarked', 'Sex','Title']\n",
    "categorical_processor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['Family_size', 'Pclass']\n",
    "ordinal_processor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_processor, numeric_features),\n",
    "        ('cat', categorical_processor, categorical_features),\n",
    "        ('ord', ordinal_processor, ordinal_features)],\n",
    "         remainder='drop') # drop \"Name\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('get family_size', family_size_processor),\n",
    "                           ('get title', title_processor),\n",
    "                           ('preprocessor', feature_processor),\n",
    "                           ('polynomial', PolynomialFeatures(degree=2)), # add polynomial combinations of the features\n",
    "                           ('clf',knn_clf)   \n",
    "                          ])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'clf__n_neighbors': list(range(1,21)),\n",
    "    'clf__weights' : ['uniform','distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and fit the grid\n",
    "grid = GridSearchCV(pipe, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the results\n",
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyper-parameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best predictor\n",
    "best_pred = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions: Would I have survived the Titanic disaster?\n",
    "Javier = pd.DataFrame({'Pclass':[2],\n",
    "                   'Name':['Perez-Alvaro, Dr. Javier'],\n",
    "                   'Sex': ['male'],\n",
    "                   'Age': [34],\n",
    "                   'SibSp': [0],\n",
    "                   'Parch': [0],\n",
    "                   'Fare': [30],\n",
    "                   'Embarked': ['S']})\n",
    "Javier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred.predict(Javi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_test_pred) # percentage of correct predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
