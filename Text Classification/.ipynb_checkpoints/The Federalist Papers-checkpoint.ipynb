{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Predicting Authorship of the Disputed Federalist Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Federalist Papers are a collection of 85 essays written by James Madison, Alexander Hamilton, and John Jay under the collective pseudonym \"Publius\" to promote the ratification of the United States Constitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\the_federalist_papers.jpg\" width=200 height=50 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorship of most of the papers were revealed some years later by Hamilton, though his claim to authorshipt of 12 papers were disputed for nearly 200 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Author | Papers |\n",
    "| :- | -: | \n",
    "| Jay | 2, 3, 4, 5, 64\n",
    "| Madison | 10, 14, 37-48\n",
    "| Hamilton | 1, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 21-36, 59, 60, 61, 65-85\n",
    "| Hamilton and Madison | 18, 19, 20\n",
    "| Disputed | 49-58, 62, 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to use NLP and Naive Bayes to predict the author of the disputed papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "\n",
    "- [Getting and processing the data](#1.-Getting-and-processing-the-data)\n",
    "- [Logistic Regression](#2.-Logistic-Regression)\n",
    "- [Naive Bayes](#3.-Naive-Bayes-Classification)\n",
    "- [Disputed Federalist Papers](#4.-Disputed-Federalist-Papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting and processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve an electronic version of the Federalist Papers from the [Gutenberg project](http://www.gutenberg.org/). Use the search facility to search for the Federalist Papers. Several versions are available. \n",
    "We'll use the plain text version [1408-8.txt](http://www.gutenberg.org/cache/epub/1404/pg1404.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll build a dictionary that identifies the author of each Federalist paper. We'll use the phrase To the People of the state of New York to identify the beginning of a paper, and the word PUBLIUS to identify the end of a paper (The word PUBLIUS marks the end of all papers except 37; we'll need to insert PUBLIUS at the end of Paper 37 manually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data/papers.txt'\n",
    "Fed_dict = {}\n",
    "opening = 'To the People of the State of New York'\n",
    "closing = 'PUBLIUS'\n",
    "\n",
    "counter = 0\n",
    "paper = ''\n",
    "\n",
    "# build a dictionary with the Federalist papers \n",
    "with open(path) as f:\n",
    "    for string in f: #  iterate over the lines of the txt file\n",
    "        if match(opening, string):\n",
    "            paper = '' # initialize Federalist Paper as an empty string\n",
    "            counter += 1 # increase counter\n",
    "        paper = paper+' '+string.replace('\\n','') # remove end of line simbol \\n; append new line; \n",
    "        if match(closing, string):\n",
    "            Fed_dict[counter]=paper # done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Fed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To the People of the State of New York:  AFTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To the People of the State of New York:  WHEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the People of the State of New York:  IT I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To the People of the State of New York:  MY L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To the People of the State of New York:  QUEE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paper\n",
       "1   To the People of the State of New York:  AFTE...\n",
       "2   To the People of the State of New York:  WHEN...\n",
       "3   To the People of the State of New York:  IT I...\n",
       "4   To the People of the State of New York:  MY L...\n",
       "5   To the People of the State of New York:  QUEE..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the Federalist Papers into a DataFrame\n",
    "papers = pd.DataFrame.from_dict(Fed_dict, orient='index',columns=['paper'])\n",
    "papers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorship function\n",
    "def author(paper_num):\n",
    "    'it returns the author of a Federalist Paper'\n",
    "    # papers authored by Jay:\n",
    "    Jay_list = [2,3,4,5,64]\n",
    "    # papers authored by Madison:\n",
    "    Madison_list = [10,14]+list(range(37,49))\n",
    "    # papers authored by Hamilton\n",
    "    Hamilton_list = [1,6,7,8,9,11,12,13,15,16,17]+list(range(21,37))+[59,60,61]+list(range(65,86))\n",
    "    # papers authored by Hamilton+Madison\n",
    "    Hamilton_Madison_list = [18,19,20]\n",
    "    # disputed papers\n",
    "    disputed_list = list(range(49,59))+[62,63]\n",
    "    if paper_num in Jay_list:\n",
    "        return 'Jay'\n",
    "    elif paper_num in Hamilton_list:\n",
    "        return 'Hamilton'\n",
    "    elif paper_num in Madison_list:\n",
    "        return 'Madison'\n",
    "    elif paper_num in Hamilton_Madison_list:\n",
    "        return 'Hamilton+Madison'\n",
    "    elif paper_num in disputed_list:\n",
    "        return 'Disputed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To the People of the State of New York:  AFTE...</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To the People of the State of New York:  WHEN...</td>\n",
       "      <td>Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the People of the State of New York:  IT I...</td>\n",
       "      <td>Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To the People of the State of New York:  MY L...</td>\n",
       "      <td>Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To the People of the State of New York:  QUEE...</td>\n",
       "      <td>Jay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paper    author\n",
       "1   To the People of the State of New York:  AFTE...  Hamilton\n",
       "2   To the People of the State of New York:  WHEN...       Jay\n",
       "3   To the People of the State of New York:  IT I...       Jay\n",
       "4   To the People of the State of New York:  MY L...       Jay\n",
       "5   To the People of the State of New York:  QUEE...       Jay"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add column author to DataFrame\n",
    "papers['author'] = papers.index.map(author)\n",
    "papers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamilton            51\n",
       "Madison             14\n",
       "Disputed            12\n",
       "Jay                  5\n",
       "Hamilton+Madison     3\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.author.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_train = papers[papers.author.isin(['Hamilton','Madison','Jay'])]\n",
    "papers_test = papers[papers.author=='Disputed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers_train), len(papers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** extract feature matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = papers_train.paper\n",
    "y_train = papers_train.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = papers_test.paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn training data vocabulary\n",
    "vect.fit(X_train)\n",
    "# create document-term matrix\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression(max_iter=2000)\n",
    "\n",
    "log_clf.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: we don't have labels for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1** (not recommended): train and test on the same set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = log_clf.predict(X_train_dtm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  0,  0],\n",
       "       [ 0,  5,  0],\n",
       "       [ 0,  0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction function has an accuracy rate of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2** (recommended): use [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72222222, 0.88888889, 0.88235294, 0.58823529])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_clf,X_train_dtm,y_train,cv=4,scoring='accuracy') # we'll use a small number of folds (cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "nb_clf.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = nb_clf.predict(X_train_dtm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  0,  0],\n",
       "       [ 0,  5,  0],\n",
       "       [ 0,  0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option 1\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72222222, 0.77777778, 0.76470588, 0.76470588])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(nb_clf,X_train_dtm,y_train,cv=4,scoring='accuracy') # we'll use a small number of folds (cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Disputed Federalist Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hamilton', 'Hamilton', 'Madison', 'Hamilton', 'Hamilton',\n",
       "       'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton',\n",
       "       'Madison', 'Madison'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression prediction\n",
    "y_test_pred = log_clf.predict(X_test_dtm)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hamilton', 'Madison', 'Madison', 'Hamilton', 'Hamilton',\n",
       "       'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton',\n",
       "       'Hamilton', 'Hamilton'], dtype='<U8')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive Bayes prediction\n",
    "y_test_pred = nb_clf.predict(X_test_dtm)\n",
    "y_test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
