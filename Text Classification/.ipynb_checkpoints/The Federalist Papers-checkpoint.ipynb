{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Predicting Authorship of the Disputed Federalist Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Federalist Papers are a collection of 85 essays written by James Madison, Alexander Hamilton, and John Jay under the collective pseudonym \"Publius\" to promote the ratification of the United States Constitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\the_federalist_papers.jpg\" width=200 height=50 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorship of most of the papers were revealed some years later by Hamilton, though his claim to authorshipt of 12 papers were disputed for nearly 200 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Author | Papers |\n",
    "| :- | -: | \n",
    "| Jay | 2, 3, 4, 5, 64\n",
    "| Madison | 10, 14, 37-48\n",
    "| Hamilton | 1, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 21-36, 59, 60, 61, 65-85\n",
    "| Hamilton and Madison | 18, 19, 20\n",
    "| Disputed | 49-58, 62, 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to use NLP and Naive Bayes to predict the author of the disputed papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "\n",
    "- [Getting and processing the data](#1.-Getting-and-processing-the-data)\n",
    "- [Logistic Regression](#2.-Logistic-Regression)\n",
    "- [Naive Bayes](#3.-Naive-Bayes-Classification)\n",
    "- [Disputed Federalist Papers](#4.-Disputed-Federalist-Papers)\n",
    "- [How does Naive Bayes choose between Hamilton and Madison](#5.-How-does-Naive-Bayes-choose-between-Hamilton-and-Madison)\n",
    "- [Parameter tuning using grid search](#6.-Parameter-tuning-using-grid-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting and processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve an electronic version of the Federalist Papers from the [Gutenberg project](http://www.gutenberg.org/). Use the search facility to search for the Federalist Papers. Several versions are available. \n",
    "We'll use the plain text version [1408-8.txt](http://www.gutenberg.org/cache/epub/1404/pg1404.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll build a dictionary that identifies the author of each Federalist paper. We'll use the phrase To the People of the state of New York to identify the beginning of a paper, and the word PUBLIUS to identify the end of a paper (The word PUBLIUS marks the end of all papers except 37; we'll need to insert PUBLIUS at the end of Paper 37 manually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data/papers.txt'\n",
    "Fed_dict = {}\n",
    "opening = 'To the People of the State of New York'\n",
    "closing = 'PUBLIUS'\n",
    "\n",
    "counter = 0\n",
    "paper = ''\n",
    "\n",
    "# build a dictionary with the Federalist papers \n",
    "with open(path) as f:\n",
    "    for string in f: #  iterate over the lines of the txt file\n",
    "        if match(opening, string):\n",
    "            paper = '' # initialize Federalist Paper as an empty string\n",
    "            counter += 1 # increase counter\n",
    "        paper = paper+' '+string.replace('\\n','') # remove end of line simbol \\n; append new line; \n",
    "        if match(closing, string):\n",
    "            Fed_dict[counter]=paper # done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Fed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To the People of the State of New York:  AFTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To the People of the State of New York:  WHEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the People of the State of New York:  IT I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To the People of the State of New York:  MY L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To the People of the State of New York:  QUEE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paper\n",
       "1   To the People of the State of New York:  AFTE...\n",
       "2   To the People of the State of New York:  WHEN...\n",
       "3   To the People of the State of New York:  IT I...\n",
       "4   To the People of the State of New York:  MY L...\n",
       "5   To the People of the State of New York:  QUEE..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the Federalist Papers into a DataFrame\n",
    "papers = pd.DataFrame.from_dict(Fed_dict, orient='index',columns=['paper'])\n",
    "papers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorship function\n",
    "def author(paper_num):\n",
    "    'it returns the author of a Federalist Paper'\n",
    "    # papers authored by Jay:\n",
    "    Jay_list = [2,3,4,5,64]\n",
    "    # papers authored by Madison:\n",
    "    Madison_list = [10,14]+list(range(37,49))\n",
    "    # papers authored by Hamilton\n",
    "    Hamilton_list = [1,6,7,8,9,11,12,13,15,16,17]+list(range(21,37))+[59,60,61]+list(range(65,86))\n",
    "    # papers authored by Hamilton+Madison\n",
    "    Hamilton_Madison_list = [18,19,20]\n",
    "    # disputed papers\n",
    "    disputed_list = list(range(49,59))+[62,63]\n",
    "    if paper_num in Jay_list:\n",
    "        return 'Jay'\n",
    "    elif paper_num in Hamilton_list:\n",
    "        return 'Hamilton'\n",
    "    elif paper_num in Madison_list:\n",
    "        return 'Madison'\n",
    "    elif paper_num in Hamilton_Madison_list:\n",
    "        return 'Hamilton+Madison'\n",
    "    elif paper_num in disputed_list:\n",
    "        return 'Disputed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To the People of the State of New York:  AFTE...</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To the People of the State of New York:  WHEN...</td>\n",
       "      <td>Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the People of the State of New York:  IT I...</td>\n",
       "      <td>Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To the People of the State of New York:  MY L...</td>\n",
       "      <td>Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To the People of the State of New York:  QUEE...</td>\n",
       "      <td>Jay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paper    author\n",
       "1   To the People of the State of New York:  AFTE...  Hamilton\n",
       "2   To the People of the State of New York:  WHEN...       Jay\n",
       "3   To the People of the State of New York:  IT I...       Jay\n",
       "4   To the People of the State of New York:  MY L...       Jay\n",
       "5   To the People of the State of New York:  QUEE...       Jay"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add column author to DataFrame\n",
    "papers['author'] = papers.index.map(author)\n",
    "papers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamilton            51\n",
       "Madison             14\n",
       "Disputed            12\n",
       "Jay                  5\n",
       "Hamilton+Madison     3\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.author.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_train = papers[papers.author.isin(['Hamilton','Madison','Jay'])]\n",
    "papers_test = papers[papers.author=='Disputed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers_train), len(papers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** extract feature matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = papers_train.paper\n",
    "y_train = papers_train.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = papers_test.paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn training data vocabulary\n",
    "vect.fit(X_train)\n",
    "# create document-term matrix\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression(max_iter=2000)\n",
    "\n",
    "log_clf.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: we don't have labels for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1** (not recommended): train and test on the same set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = log_clf.predict(X_train_dtm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  0,  0],\n",
       "       [ 0,  5,  0],\n",
       "       [ 0,  0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction function has an accuracy rate of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2** (recommended): use [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72222222, 0.88888889, 0.88235294, 0.58823529])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_clf,X_train_dtm,y_train,cv=4,scoring='accuracy') # we'll use a small number of folds (cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "nb_clf.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = nb_clf.predict(X_train_dtm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  0,  0],\n",
       "       [ 0,  5,  0],\n",
       "       [ 0,  0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option 1\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72222222, 0.77777778, 0.76470588, 0.76470588])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option 2\n",
    "scores = cross_val_score(nb_clf,X_train_dtm,y_train,cv=4,scoring='accuracy') # we'll use a small number of folds (cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7573529411764706"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Disputed Federalist Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hamilton', 'Hamilton', 'Madison', 'Hamilton', 'Hamilton',\n",
       "       'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton',\n",
       "       'Madison', 'Madison'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression prediction\n",
    "y_test_pred = log_clf.predict(X_test_dtm)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hamilton', 'Madison', 'Madison', 'Hamilton', 'Hamilton',\n",
       "       'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton',\n",
       "       'Hamilton', 'Hamilton'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive Bayes prediction\n",
    "y_test_pred = nb_clf.predict(X_test_dtm)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How does Naive Bayes choose between Hamilton and Madison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_words = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '10', '11', '1685', '1688', '1706', '1774', '1783', '1784', '1786', '1787', '1808', '195', '1st', '2d', '30', '3d', '4th', '5th', 'abandon', 'abandoned', 'abandoning', 'abate', 'abetted', 'abilities', 'ability', 'able', 'ablest', 'abolish', 'abolished', 'abolishing', 'abolition', 'abortive', 'abounding', 'abounds', 'abridge', 'abridged', 'abridgements', 'abridging', 'abridgment', 'abroad', 'abrogate', 'abrogating', 'absence', 'absolute', 'absolutely', 'absolves', 'absorb', 'absorbed', 'abstain']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 words\n",
    "print(X_train_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['witnesses', 'witty', 'wolsey', 'woman', 'womb', 'won', 'wonder', 'wondered', 'wonderful', 'wood', 'word', 'words', 'work', 'workings', 'works', 'world', 'worn', 'worse', 'worst', 'worthy', 'wound', 'wounded', 'wreaked', 'wreck', 'wretched', 'writ', 'write', 'writer', 'writers', 'writing', 'writings', 'written', 'wrong', 'wrought', 'wyoming', 'xiv', 'yards', 'year', 'years', 'yeomanry', 'yes', 'yield', 'yielding', 'yoke', 'yokes', 'york', 'young', 'zaleucus', 'zeal', 'zealous']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 words\n",
    "print(X_train_words[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  1.,  1., ...,  0., 12.,  6.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  9.,  2.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each word appears in each class\n",
    "nb_clf.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7732)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes (Hamilton, Madison, Jay), columns represent words\n",
    "nb_clf.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hamilton', 'Jay', 'Madison'], dtype='<U8')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times each word appears across all Hamilton's papers\n",
    "Hamilton_word_count = nb_clf.feature_count_[0,:]\n",
    "# number of times each word appears across all Madison's papers\n",
    "Madison_word_count = nb_clf.feature_count_[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamilton</th>\n",
       "      <th>Madison</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hamilton  Madison\n",
       "word                   \n",
       "000        2.0      0.0\n",
       "10         1.0      0.0\n",
       "11         1.0      0.0\n",
       "1685       0.0      0.0\n",
       "1688       2.0      0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of words with their separate Hamilton and Madison counts\n",
    "words = pd.DataFrame({'word' : X_train_words, 'Hamilton' : Hamilton_word_count, 'Madison' : Madison_word_count}).set_index('word')\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamilton</th>\n",
       "      <th>Madison</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mitigation</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>circumstance</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instantly</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whomsoever</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mind</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Hamilton  Madison\n",
       "word                           \n",
       "mitigation         2.0      0.0\n",
       "circumstance      28.0      2.0\n",
       "instantly          2.0      1.0\n",
       "whomsoever         1.0      0.0\n",
       "mind              15.0      6.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "words.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 1 to Hamilton and Madison counts to avoid dividing by 0\n",
    "words.Hamilton = words.Hamilton+1\n",
    "words.Madison = words.Madison+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Hamilton and Madison counts into frequencies\n",
    "words.Hamilton = words.Hamilton/words.Hamilton.sum()\n",
    "words.Madison = words.Madison/words.Madison.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamilton</th>\n",
       "      <th>Madison</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arrayed</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>territorial</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advantageous</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ready</th>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chimeras</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Hamilton   Madison\n",
       "word                            \n",
       "arrayed       0.000019  0.000085\n",
       "territorial   0.000058  0.000043\n",
       "advantageous  0.000019  0.000085\n",
       "ready         0.000443  0.000256\n",
       "chimeras      0.000038  0.000043"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ration of Hamilton-to-Madison and Madison-to-Hamilton for each word\n",
    "words['Hamilton_ratio'] = words.Hamilton/words.Madison\n",
    "words['Madison_ratio'] = words.Madison/words.Hamilton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamilton</th>\n",
       "      <th>Madison</th>\n",
       "      <th>Hamilton_ratio</th>\n",
       "      <th>Madison_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accomplishes</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.225143</td>\n",
       "      <td>4.441614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated</th>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>2.341491</td>\n",
       "      <td>0.427078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigotry</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.900574</td>\n",
       "      <td>1.110403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agreement</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.225143</td>\n",
       "      <td>4.441614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partly</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.128653</td>\n",
       "      <td>7.772824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Hamilton   Madison  Hamilton_ratio  Madison_ratio\n",
       "word                                                           \n",
       "accomplishes  0.000019  0.000085        0.225143       4.441614\n",
       "calculated    0.000500  0.000214        2.341491       0.427078\n",
       "bigotry       0.000038  0.000043        0.900574       1.110403\n",
       "agreement     0.000019  0.000085        0.225143       4.441614\n",
       "partly        0.000038  0.000299        0.128653       7.772824"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamilton</th>\n",
       "      <th>Madison</th>\n",
       "      <th>Hamilton_ratio</th>\n",
       "      <th>Madison_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kind</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>17.336041</td>\n",
       "      <td>0.057683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intended</th>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>16.210324</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>readily</th>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>11.257169</td>\n",
       "      <td>0.088832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>community</th>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>10.506691</td>\n",
       "      <td>0.095177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonly</th>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>10.356596</td>\n",
       "      <td>0.096557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomination</th>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>10.356596</td>\n",
       "      <td>0.096557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thirds</th>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>9.906309</td>\n",
       "      <td>0.100946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matters</th>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>9.456022</td>\n",
       "      <td>0.105753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information</th>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>9.005735</td>\n",
       "      <td>0.111040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formation</th>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>9.005735</td>\n",
       "      <td>0.111040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Hamilton   Madison  Hamilton_ratio  Madison_ratio\n",
       "word                                                          \n",
       "kind         0.001482  0.000085       17.336041       0.057683\n",
       "intended     0.000693  0.000043       16.210324       0.061689\n",
       "readily      0.000481  0.000043       11.257169       0.088832\n",
       "community    0.001347  0.000128       10.506691       0.095177\n",
       "commonly     0.000443  0.000043       10.356596       0.096557\n",
       "nomination   0.000443  0.000043       10.356596       0.096557\n",
       "thirds       0.000423  0.000043        9.906309       0.100946\n",
       "matters      0.000404  0.000043        9.456022       0.105753\n",
       "information  0.000385  0.000043        9.005735       0.111040\n",
       "formation    0.000385  0.000043        9.005735       0.111040"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 Hamiltonian words\n",
    "words.sort_values(by='Hamilton_ratio', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamilton</th>\n",
       "      <th>Madison</th>\n",
       "      <th>Hamilton_ratio</th>\n",
       "      <th>Madison_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>democracy</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.040935</td>\n",
       "      <td>24.428877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justices</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.045029</td>\n",
       "      <td>22.208070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reform</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.056286</td>\n",
       "      <td>17.766456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assumed</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.056286</td>\n",
       "      <td>17.766456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indirectly</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>15.545649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whilst</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.069275</td>\n",
       "      <td>14.435245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thirty</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.075048</td>\n",
       "      <td>13.324842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unanimous</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.075048</td>\n",
       "      <td>13.324842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enlarge</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.075048</td>\n",
       "      <td>13.324842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.075048</td>\n",
       "      <td>13.324842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hamilton   Madison  Hamilton_ratio  Madison_ratio\n",
       "word                                                         \n",
       "democracy   0.000019  0.000470        0.040935      24.428877\n",
       "justices    0.000019  0.000427        0.045029      22.208070\n",
       "reform      0.000019  0.000342        0.056286      17.766456\n",
       "assumed     0.000019  0.000342        0.056286      17.766456\n",
       "indirectly  0.000019  0.000299        0.064327      15.545649\n",
       "whilst      0.000038  0.000556        0.069275      14.435245\n",
       "thirty      0.000019  0.000256        0.075048      13.324842\n",
       "unanimous   0.000019  0.000256        0.075048      13.324842\n",
       "enlarge     0.000019  0.000256        0.075048      13.324842\n",
       "patient     0.000019  0.000256        0.075048      13.324842"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 Madisonian words\n",
    "words.sort_values(by='Madison_ratio', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter tuning using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('naive_bayes', MultinomialNB())])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=\n",
    "               [('vect', CountVectorizer()),\n",
    "                #('tfidf', TfidfTransformer()),\n",
    "                ('naive_bayes', MultinomialNB())])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter dictionary\n",
    "param_dict = {'vect__ngram_range': [(1, 1), (1, 2)], # (1,1) : use 1-grams (words); (1,2) : use 1 and 2 grams\n",
    "              'vect__stop_words' : ['english',None],\n",
    "              #'tfidf__use_idf': (True, False),\n",
    "              'naive_bayes__alpha' : [0.0001, 0.001, 0.01,0.1, 1]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "grid = GridSearchCV(pipe, param_dict, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('naive_bayes', MultinomialNB())]),\n",
       "             param_grid={'naive_bayes__alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vect__stop_words': ['english', None]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146135265700484"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes__alpha': 0.1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': None}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('naive_bayes', MultinomialNB())])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predictor = grid.estimator\n",
    "best_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hamilton', 'Madison', 'Madison', 'Hamilton', 'Hamilton',\n",
       "       'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton',\n",
       "       'Hamilton', 'Hamilton'], dtype='<U8')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predictor.fit(X_train,y_train)\n",
    "y_test_pred = best_predictor.predict(X_test)\n",
    "y_test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
