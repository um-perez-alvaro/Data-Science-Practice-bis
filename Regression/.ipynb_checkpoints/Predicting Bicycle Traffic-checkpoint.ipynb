{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting bicycle traffic across Seattle's Fremont Bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fremont Bridge Bicycle Counter began operation in October 2012 and records the number of bikes that cross the bridge using the pedestrian/bicycle pathways.\n",
    "The bicycle counter has sensors on the east and west sidewalks of the bridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"fremont.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"fremont2.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dayly weather data from the [NOAA](https://www.ncdc.noaa.gov/cdo-web/search). Station ID: USW00024233 (SEATTLE TACOMA AIRPORT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seattle's Fremont Bridge Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Fremont dataset from the [Seattle Open Data Portal](https://data.seattle.gov/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'load the dataset'\n",
    "name = 'Fremont_Bridge_Bicycle_Counter.csv'\n",
    "Fremont = pd.read_csv(name, index_col='Date', parse_dates=True)\n",
    "Fremont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'time range'\n",
    "Fremont.index.max(), Fremont.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'drop Fremont Bridge East Sidewalk and Fremont Bridge West Sidewalk columns'\n",
    "Fremont.drop(['Fremont Bridge East Sidewalk','Fremont Bridge West Sidewalk'],axis=1,inplace=True)\n",
    "' change column names'\n",
    "Fremont.columns = ['Total']\n",
    "Fremont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'total daily bicycle traffic'\n",
    "Fremont_daily = Fremont.resample('d').sum() \n",
    "Fremont_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fremont_daily.plot(figsize=(12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'2020'\n",
    "Fremont_daily[Fremont_daily.index.year==2020].resample('M').sum().plot(figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'2019'\n",
    "Fremont_daily[Fremont_daily.index.year==2019].resample('M').sum().plot(figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'add column that indicates the day of the week/month/year'\n",
    "#day_of_week_map = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\n",
    "Fremont_daily['day_of_week'] = Fremont_daily.index.dayofweek\n",
    "'add month and year columns'\n",
    "Fremont_daily['month'] = Fremont_daily.index.month\n",
    "Fremont_daily['year'] = Fremont_daily.index.year\n",
    "Fremont_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'add a column that indicates whether or not a day is a holiday'\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays('2012-10-03 00:00:00','2020-09-30')\n",
    "Fremont_daily = Fremont_daily.join(pd.Series(1, index=holidays,name='holiday'))\n",
    "Fremont_daily['holiday'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'add hours_of_daylight column'\n",
    "def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
    "    'this function computes the hours of daylight for a particular date and latitude'\n",
    "    days = (date-pd.to_datetime('2000-12-21')).days\n",
    "    m = (1. - np.tan(np.radians(latitude)) * np.tan(np.radians(axis) * np.cos(days*2*np.pi/365.25)))\n",
    "    return 24*np.degrees(np.arccos(1-m))/ 180\n",
    "    #return 24.*np.degrees(np.arccos(1-np.clip(m,0,2,))) / 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'add hours_of_daylight column'\n",
    "def hours_of_daylight_2(date, axis=23.44, latitude=47.61):\n",
    "    'this function computes the hours of daylight for a particular date and latitude'\n",
    "    days = (date-pd.to_datetime('2000-12-21')).days\n",
    "    m = (1. - np.tan(np.radians(latitude)) * np.tan(np.radians(axis) * np.cos(days*2*np.pi/365.25)))\n",
    "    return 24.*np.degrees(np.arccos(1-np.clip(m,0,2,))) / 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fremont_daily['daylight_hrs'] = Fremont_daily.index.map(hours_of_daylight)\n",
    "Fremont_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fremont_daily['daylight_hrs_2'] = Fremont_daily.index.map(hours_of_daylight_2)\n",
    "Fremont_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fremont_daily.daylight_hrs.plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fremont_daily.daylight_hrs_2.plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Fremont_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(r'Data/weather.csv', index_col='DATE', parse_dates=True)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.index.max(),Fremont_daily.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AWND = Average daily wind speed\n",
    "- PGTM = Peak gust time (HHMM)\n",
    "- PRCP = Precipitation\n",
    "- SNOW = Snowfall \n",
    "- SNWD = Snow depth \n",
    "- TAVG = Average temperature\n",
    "- TMAX = Maximum temperature\n",
    "- TMIN = Maximum temperature\n",
    "- WDF2 = Direction of fastest 2-minute wind (degrees)\n",
    "- WDF5 = Direction of fastest 5-second wind (degrees)\n",
    "- WSF2 = Fastest 2-minute wind speed (tenths of meters per second)\n",
    "- WSF5 = Fastest 5-second wind speed (tenths of meters per second)\n",
    "- WT** = Weather Type where ** has one of the following values:\n",
    "    - 01 = Fog, ice fog, or freezing fog (may include heavy fog)\n",
    "    - 02 = Heavy fog or heaving freezing fog (not always distinquished from fog)\n",
    "\t- 03 = Thunder\n",
    "    - 04 = Ice pellets, sleet, snow pellets, or small hail \n",
    "    - 05 = Hail (may include small hail)   \n",
    "    - 08 = Smoke or haze \n",
    "    - 09 = Blowing or drifting snow\n",
    "    - 13 = Mist\n",
    "    - 14 = Drizzle   \n",
    "    - 16 = Rain (may include freezing rain, drizzle, and freezing drizzle) \n",
    "    - 18 = Snow, snow pellets, snow grains, or ice crystals\n",
    "    - 22 = Ice fog or freezing fog\n",
    "                  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"missing values\"\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'drop columns that we will not use'\n",
    "weather.drop(['STATION','NAME','PGTM'],axis=1, inplace=True)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAVG column has some missing values \n",
    "weather.TAVG.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix TAVG column\n",
    "weather.TAVG.fillna(0.5*(weather.TMAX+weather.TMIN), inplace=True)\n",
    "weather.TAVG.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot max and min temperatures\n",
    "weather.TMAX.plot()\n",
    "weather.TMIN.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precipitation\n",
    "weather.PRCP.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snowfall\n",
    "weather.SNOW.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snow depth\n",
    "weather.SNWD.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge weather and daily datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fremont_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily=Fremont_daily.join(weather)\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'add annual and annual_squared columns'\n",
    "daily['annual'] = (daily.index-daily.index[0]).days/365\n",
    "daily['annual_squared'] = daily.annual*daily.annual\n",
    "daily.drop('year',axis=1,inplace=True)\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'drop 2020'\n",
    "daily = daily[daily.index<pd.to_datetime('2020/01/01')]\n",
    "daily.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = daily['Total'] # target vector\n",
    "X = daily.iloc[:,1:10] # feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ColumnTransformer(transformers = [\n",
    "    ('encoder', OneHotEncoder(), ['day_of_week', 'month','holiday'])],\n",
    "    remainder=StandardScaler()) #'passthrough'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.fit_transform(X)[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('processor', processor),\n",
    "    ('poly_features', PolynomialFeatures(degree=1, include_bias=False)),\n",
    "    ('reg', Lasso(alpha=1))\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute predictions\n",
    "daily['predicted'] = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot actual and predicted values\n",
    "daily[['Total','predicted']].plot(alpha=0.5, figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'plot actual and predicted monthly values'\n",
    "daily.Total.resample('m').sum().plot(figsize=(12,5))\n",
    "daily.predicted.resample('m').sum().plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'plot actual and predicted yearly values'\n",
    "daily.Total.resample('y').sum().plot(figsize=(12,5))\n",
    "daily.predicted.resample('y').sum().plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pipe['reg'].coef_\n",
    "len(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(pipe['processor'].named_transformers_['encoder'].get_feature_names(['day_of_week','month','holiday']))+['year','daylight_hrs','AWND','PRCP','SNOW','SNWD']\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_feature_names = pipe['poly_features'].get_feature_names(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poly_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(coeff, poly_feature_names, columns=['coefs'])\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,30))\n",
    "coefficients.coefs.sort_values().plot(kind='barh',figsize=(12,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients[coefficients.index=='year^2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'poly_features__degree' : [1,2,3],\n",
    "          'reg__alpha' : [0.001,0.01,0.1,1,10,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe,params,cv=5,scoring='neg_root_mean_squared_error',n_jobs=-1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)[['mean_test_score', 'params']]\n",
    "results.mean_test_score.plot(marker='o')\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
